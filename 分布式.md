
### 分布式
关于分布式的一系列问题【http://www.wangzha.tech/archives/distributed-system-interview】

#### 分布式session
1. spring session + redis 请求创建session时spring session会将生成的session存到指定的Redis，当客户端再次发来请求时spring session会从Redis里面读取原来的session；
2. JWT(JSON Web Token) 生成身份验证token；

#### 分布式事务了解吗？你们是如何解决分布式事务问题的？
[http://www.wangzha.tech/archives/distributed-transaction]

分布式事务的实现主要有以下 5 种方案：
1. TCC 方案
2. 可靠消息最终一致性方案
3. XA 方案（不推荐）
4. 本地消息表（不推荐）
5. 最大努力通知方案

###### TCC（Try、Confirm、Cancel）
Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。
Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。
Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。

这种方案说实话几乎很少人使用，自己手写回滚逻辑，或者是补偿逻辑，代价太大，业务代码很难维护。
一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。

###### 可靠消息最终一致性方案

直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。
大概的意思就是：
1. A系统先发送一个 prepared 消息到 mq，如果消息发送失败那么就直接取消操作；如果发送成功，那么接着执行本地事务，事务实行成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；

2. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；

3. mq 会自动定时轮询所有 prepared 消息并回调你的接口，确认这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？通常你的接口接口可以查下数据库看之前本地事务是否执行，如果回滚了，那么告诉mq回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。

4. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。

这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。


###### XA（二段提交）（不推荐）
适用于单模块对应多个数据库的应用，存在一个类似管理器的概念，管理器在提交事务之前会先确认是否每个数据库都已经准备好，都ok的情况下再正式提交事务；如果有一个不ok，回滚事务；
缺点：严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景；

###### 本地消息表（不推荐）
这个大概意思是这样的：
A 系统在自己本地一个事务里操作同时，插入一条数据到消息表；
接着 A 系统将这个消息发送到 MQ 中去；
B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息；
B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态；
如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理；
这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。
这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的，会导致如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。

###### 最大努力通知方案
这个方案的大致意思就是：

系统 A 本地事务执行完之后，发送个消息到 MQ；
这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；
要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。

###### 你们公司是如何处理分布式事务的？
如果你真的被问到，可以这么说，我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。

### 保证接口幂等性
这个不是技术问题，这个没有通用的一个方法，这个应该结合业务来保证幂等性。

所谓幂等性，就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，比如不能多扣款、不能多插入一条数据、不能将统计值多加了 1。这就是幂等性。

其实保证幂等性主要是三点：

对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。
每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。
每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。
实际运作过程中，你要结合自己的业务来，比如说利用 redis，用 orderId 作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款。

### 保证分布式服务的有序性
首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个内存队列里去，强制排队，这样来确保他们的顺序性。

但是这样引发的后续问题就很多，比如说要是某个订单对应的请求特别多，造成某台机器成热点怎么办？解决这些问题又要开启后续一连串的复杂技术方案......曾经这类问题弄的我们头疼不已，所以，还是建议什么呢？

最好是比如说刚才那种，一个订单的插入和删除操作，能不能合并成一个操作，就是一个删除，或者是什么，避免这种问题的产生。

### dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
【http://www.wangzha.tech/archives/dubbo-load-balancing】
dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡；
网络通信、序列化：dubbo 协议、长连接、NIO、hessian 序列化协议；
负载均衡策略、集群容错策略、动态代理策略：dubbo 跑起来的时候一些功能是如何运转的？怎么做负载均衡？怎么做集群容错？怎么生成动态代理？
dubbo SPI 机制：你了解不了解 dubbo 的 SPI 机制？如何基于 SPI 机制对 dubbo 进行扩展？

###### 负载均衡策略：
1. random loadbalance（默认，随机，按权重随机）
随机策略
1.1 如果总权重大于0并且权重不相同，就生成一个1~totalWeight(总权重数)的随机数，然后再把随机数和所有的权重值一一相减得到一个新的随机数，直到随机 数小于0，那么此时访问的服务器就是使得随机数小于0的权重所在的机器；
1.2 如果权重相同或者总权重数为0，就生成一个1~length(权重的总个数)的随机数，此时所访问的机器就是这个随机数对应的权重所在的机器

2.RoundRobin LoadBalance（轮询）
2.1 轮循，按公约后的权重设置轮循比率。
2.2 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。
2.3 轮询策略
2.3.1 如果权重不一样时，获取一个当前的权重基数，然后从权重集合中筛选权重大于当前权重基数的集合，如果筛选出的集合的长度为1，此时所访问的机器就是集合里面的权重对应的机器
2.3.2 如果权重一样时就取模轮循

3、LeastActive LoadBalance
3.1 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差(调用前的时刻减去响应后的时刻的值)。
3.2 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大

4、ConsistentHash LoadBalance
4.1 一致性 Hash，相同参数的请求总是发到同一提供者。
4.2 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。
4.3 缺省只对第一个参数 Hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />
4.4 缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />

###### dubbo 集群容错策略
failover cluster 模式
失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器）

failfast cluster模式
一次调用失败就立即失败，常见于写操作。（调用失败就立即失败）

failsafe cluster 模式
出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

failback cluster 模式
失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

forking cluster 模式
并行调用多个 provider，只要一个成功就立即返回。

broadcacst cluster
逐个调用所有的 provider。

###### dubbo动态代理策略
默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。

### 深入理解SPI机制
【https://www.jianshu.com/p/3a3edbcd8f24】
SPI 全称为 (Service Provider Interface) ,是JDK内置的一种服务提供发现机制。 目前有不少框架用它来做服务的扩展发现， 简单来说，它就是一种动态替换发现的机制， 举个例子来说， 有个接口，想运行时动态的给它添加实现，你只需要添加一个实现。
具体是在JAR包的"src/META-INF/services/"目录下建立一个文件，文件名是接口的全限定名，文件的内容可以有多行，每行都是该接口对应的具体实现类的全限定名.
这一机制为很多框架扩展提供了可能，比如在Dubbo、JDBC中都使用到了SPI机制。


### 分布式锁
实现方式：数据库乐观锁、Redis、Zookeeper

###### 基于数据库的乐观锁实现
表中添加一个时间戳或者版本号的字段来实现，update xx set version = new... where id = y and version = old 当更新不成功，
客户端重试，重新读取最新的版本号或时间戳，再次尝试更新，类似 CAS 机制，推荐使用。

###### zookeeper创建临时有序节点
开发常用，如果你的项目中正好使用了zk集群，推荐使用。
业界有Apache Curator框架提供了现成的分布式锁功能，现成的，推荐直接使用。
另外，可基于Zookeeper自身的特性和原生Zookeeper API自行实现分布式锁。

1. 多个线程竞争锁，就是按顺序在锁节点下创建一个接一个的临时有序子节点；
2. 若果不是第一个节点则监听前一个节点；
3. 如果自己前面一个节点释放，则往前移一位；
4. 所释放时会通知监听这个锁的监听器，监听器通知对应节点尝试获取锁；
5. 如果线程所在的客户端宕机，那么zk是可以感知到的，会删除对应的节点；

番外：Curator框架已经实现zk的封装，可以参考

###### Redis 实现
开发常用，如果你的项目中正好使用了redis，不想引入额外的分布式锁组件，推荐使用。
业界也提供了多个现成好用的框架予以支持分布式锁，比如Redisson、spring-integration-redis、redis自带的setnx命令，推荐直接使用。
另外，可基于redis命令和redis lua支持的原子特性，自行实现分布式锁。

方式一：lua脚本

// 加锁脚本，KEYS[1] 要加锁的key，ARGV[1]是UUID随机值，ARGV[2]是过期时间
private static final String SCRIPT_LOCK = "if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then redis.call('pexpire', KEYS[1], ARGV[2]) return 1 else return 0 end";

// 解锁脚本，KEYS[1]要解锁的key，ARGV[1]是UUID随机值
private static final String SCRIPT_UNLOCK = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";

方式二：SETNX 命令

```java
public static boolean lock(Jedis jedis, String lockKey, String requestId, int expireTime) {
        String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
        if ("OK".equals(result)) {
            return true;
        }
        return false;
    }
```
注意：过期时间需要设置合理
优化：如果加锁成功, 则开启一个定时器，每过了X(X < N, 一般可配置)秒, 就给这个锁延长Y (Y > X, 一般可配置)秒，释放锁的时候, 把定时器删掉

[https://www.cnblogs.com/lhh-north/p/11047252.html]

######  RedLock 算法
实现思路：放弃redis的主从结构, 使用N(一般是5)个redis实例来保证可用性;
  1. 计算当前时间戳CUR_T
  2. 客户端逐一向N个redis获取锁.也就是把同一个KEY和VALUE分布写到每个redis实例中,过期时间为EX_T. 获取锁的时候还需要指一个时间:
  这次set命令的响应超时时间RESP_T. 其中RESP_T < EX_T. RESP_T的存在是为了避免某个redis实例已经挂了的时候,还在苦等它响应返回.
  3. 对于第2步中的任何一个redis实例, 如果RESP_T时间内没有返回, 或者set命令返回false, 则代表获取锁失败, 否则就是获取锁成功. 不管在当前实例获取锁成功还是失败, 都立马向下一个实例获取锁.
  4. N个redis都请求完后,计算总耗时(用加锁完成时间戳-CUR_T) ,满足至少有(N/2+1)个实例能获取到锁,而且总耗时小于锁的失效时间才算获取锁成功.
  5. 如果获取锁失败,要算所有的实例unlock释放锁.
