### springboot启动流程
Springboot的启动，主要创建了配置环境(environment)、事件监听(listeners)、应用上下文(applicationContext)，并基于以上条件，在容器中开始实例化我们需要的Bean，至此，通过SpringBoot启动的程序已经构造完成。



### 分布式
关于分布式的一系列问题【http://www.wangzha.tech/archives/distributed-system-interview】

#### 分布式事务了解吗？你们是如何解决分布式事务问题的？
[http://www.wangzha.tech/archives/distributed-transaction]

分布式事务的实现主要有以下 5 种方案：
1. TCC 方案
2. 可靠消息最终一致性方案
3. XA 方案（不推荐）
4. 本地消息表（不推荐）
5. 最大努力通知方案

###### TCC（Try、Confirm、Cancel）
Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。
Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。
Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。

这种方案说实话几乎很少人使用，自己手写回滚逻辑，或者是补偿逻辑，代价太大，业务代码很难维护。
一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。

###### 可靠消息最终一致性方案

直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。
大概的意思就是：
1. A系统先发送一个 prepared 消息到 mq，如果消息发送失败那么就直接取消操作；如果发送成功，那么接着执行本地事务，事务实行成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；

2. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；

3. mq 会自动定时轮询所有 prepared 消息并回调你的接口，确认这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？通常你的接口接口可以查下数据库看之前本地事务是否执行，如果回滚了，那么告诉mq回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。

4. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。

这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。


###### XA（二段提交）（不推荐）
适用于单模块对应多个数据库的应用，存在一个类似管理器的概念，管理器在提交事务之前会先确认是否每个数据库都已经准备好，都ok的情况下再正式提交事务；如果有一个不ok，回滚事务；
缺点：严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景；

###### 本地消息表（不推荐）
这个大概意思是这样的：
A 系统在自己本地一个事务里操作同时，插入一条数据到消息表；
接着 A 系统将这个消息发送到 MQ 中去；
B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息；
B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态；
如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理；
这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。
这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的，会导致如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。

###### 最大努力通知方案
这个方案的大致意思就是：

系统 A 本地事务执行完之后，发送个消息到 MQ；
这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；
要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。

###### 你们公司是如何处理分布式事务的？
如果你真的被问到，可以这么说，我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。

### 保证接口幂等性
这个不是技术问题，这个没有通用的一个方法，这个应该结合业务来保证幂等性。

所谓幂等性，就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，比如不能多扣款、不能多插入一条数据、不能将统计值多加了 1。这就是幂等性。

其实保证幂等性主要是三点：

对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。
每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。
每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。
实际运作过程中，你要结合自己的业务来，比如说利用 redis，用 orderId 作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款。

### 保证分布式服务的有序性
首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个内存队列里去，强制排队，这样来确保他们的顺序性。

但是这样引发的后续问题就很多，比如说要是某个订单对应的请求特别多，造成某台机器成热点怎么办？解决这些问题又要开启后续一连串的复杂技术方案......曾经这类问题弄的我们头疼不已，所以，还是建议什么呢？

最好是比如说刚才那种，一个订单的插入和删除操作，能不能合并成一个操作，就是一个删除，或者是什么，避免这种问题的产生。

### dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
【http://www.wangzha.tech/archives/dubbo-load-balancing】
dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡；
网络通信、序列化：dubbo 协议、长连接、NIO、hessian 序列化协议；
负载均衡策略、集群容错策略、动态代理策略：dubbo 跑起来的时候一些功能是如何运转的？怎么做负载均衡？怎么做集群容错？怎么生成动态代理？
dubbo SPI 机制：你了解不了解 dubbo 的 SPI 机制？如何基于 SPI 机制对 dubbo 进行扩展？

###### 负载均衡策略：
1. random loadbalance（默认，随机，按权重随机）
随机策略：
1.1 如果总权重大于0并且权重不相同，就生成一个1~totalWeight(总权重数)的随机数，然后再把随机数和所有的权重值一一相减得到一个新的随机数，直到随机 数小于0，那么此时访问的服务器就是使得随机数小于0的权重所在的机器；
1.2 如果权重相同或者总权重数为0，就生成一个1~length(权重的总个数)的随机数，此时所访问的机器就是这个随机数对应的权重所在的机器

2.RoundRobin LoadBalance（轮询）
2.1 轮循，按公约后的权重设置轮循比率。
2.2 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。
2.3 轮询策略
2.3.1 如果权重不一样时，获取一个当前的权重基数，然后从权重集合中筛选权重大于当前权重基数的集合，如果筛选出的集合的长度为1，此时所访问的机器就是集合里面的权重对应的机器
2.3.2 如果权重一样时就取模轮循

3、LeastActive LoadBalance
3.1 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差(调用前的时刻减去响应后的时刻的值)。
3.2 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大

4、ConsistentHash LoadBalance
4.1 一致性 Hash，相同参数的请求总是发到同一提供者。
4.2 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。
4.3 缺省只对第一个参数 Hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />
4.4 缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />

###### dubbo 集群容错策略
failover cluster 模式
失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器）

failfast cluster模式
一次调用失败就立即失败，常见于写操作。（调用失败就立即失败）

failsafe cluster 模式
出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

failback cluster 模式
失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

forking cluster 模式
并行调用多个 provider，只要一个成功就立即返回。

broadcacst cluster
逐个调用所有的 provider。

###### dubbo动态代理策略
默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。

### 深入理解SPI机制
【https://www.jianshu.com/p/3a3edbcd8f24】
SPI 全称为 (Service Provider Interface) ,是JDK内置的一种服务提供发现机制。 目前有不少框架用它来做服务的扩展发现， 简单来说，它就是一种动态替换发现的机制， 举个例子来说， 有个接口，想运行时动态的给它添加实现，你只需要添加一个实现。
具体是在JAR包的"src/META-INF/services/"目录下建立一个文件，文件名是接口的全限定名，文件的内容可以有多行，每行都是该接口对应的具体实现类的全限定名.
这一机制为很多框架扩展提供了可能，比如在Dubbo、JDBC中都使用到了SPI机制。


### 分布式锁
###### zookeeper创建临时有序节点
1. 多个线程竞争锁，就是按顺序在锁节点下创建一个接一个的临时有序子节点；
2. 若果不是第一个节点则监听前一个节点；
3. 如果自己前面一个节点释放，则往前移一位；
4. 所释放时会通知监听这个锁的监听器，监听器通知对应节点尝试获取锁；
5. 如果线程所在的客户端宕机，那么zk是可以感知到的，会删除对应的节点；

番外：Curator框架已经实现zk的封装，可以参考

###### redis  set Nx px + lua 脚本delete + 定时器
[https://www.cnblogs.com/lhh-north/p/11047252.html]
1. 加锁, 过期时间为N秒
2. 如果加锁成功, 则开启一个定时器
3. 定时器一直在执行, 每过了X(X < N, 一般可配置)秒, 就给这个锁延长Y (Y > X, 一般可配置)秒
4. 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
```
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```
5. 释放锁的时候, 把定时器删掉
6. RedLock 算法
```
REDLOCK的实现思路就是放弃redis的主从结构, 使用N(一般是5)个redis实例来保证可用性;
  1. 计算当前时间戳CUR_T
  2. 客户端逐一向N个redis获取锁.也就是把同一个KEY和VALUE分布写到每个redis实例中,过期时间为EX_T. 获取锁的时候还需要指一个时间:
  这次set命令的响应超时时间RESP_T. 其中RESP_T < EX_T. RESP_T的存在是为了避免某个redis实例已经挂了的时候,还在苦等它响应返回.
  3. 对于第2步中的任何一个redis实例, 如果RESP_T时间内没有返回, 或者set命令返回false, 则代表获取锁失败, 否则就是获取锁成功. 不管在当前实例获取锁成功还是失败, 都立马向下一个实例获取锁.
  4. N个redis都请求完后,计算总耗时(用加锁完成时间戳-CUR_T) ,满足至少有(N/2+1)个实例能获取到锁,而且总耗时小于锁的失效时间才算获取锁成功.
  5. 如果获取锁失败,要算所有的实例unlock释放锁.
```

##### 京东金融redis实践
【https://www.infoq.cn/article/jingdong-redis-practice/】


### 分库分表中间件
###### mycat（proxy层方案）
mycat 这种 proxy 层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。

###### sharding-jdbc(当当开源的，属于 client 层方案)
sharding-jdbc 这种 client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 sharding-jdbc 的依赖；
###### 比较
通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 mycat，然后大量项目直接透明使用即可

### 分库分表策略

###### 水平

###### 垂直

### LRU 算法 （Least Recently Used 最近最少使用）
【https://juejin.im/post/5c0392656fb9a049fb4366fa】
最先应用于Linux，用于内存管理，当我们的内存容量不够的时候需要回收内存清理数据，那应该以什么样的原则去清理呢，一般认为最近很少被访问的数据将来被访问的概率也比较底，所以先清除这部分数据回收内存。
具体的算法思想：
利用双向哈希链表按最后使用时间排序，新的哈希对会排在尾部，如果前面的哈希对呗访问，那么也会移到最尾，内存不足时会先清除前面的数据，这样最近常被使用的数据得以保留。


### 如何保证消息的顺序性？
待补充
rabbitMQ 、 rocketMQ
### 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？

### 消息延时、失效如何处理？

### 消息多的装不下了如何处理？

### 如何保证消息不被重复消费？


### 缓存雪崩
名词解析：缓存服务宕机或者大部分key同一时间失效，导致大量的查询都落到数据库导致崩溃。

解决办法：
1. 针对同时失效场景：加锁排队，只能有一个线程去构建缓存，设置合理的过期时间，其他线程再从缓存拿数据；
2. 针对宕机场景：
    事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃；
    事中：本地 ehcache 缓存 + hystrix 限流 & 降级，避免 MySQL 被打死；
    事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据；
    
### 缓存穿透
名词解释：查询一个不存在的数据，那么缓存中是没有的，只能到数据库查，直接穿过缓存，要是被利用攻击，后果可想而已

解决办法：
1. bloom filter：类似于哈希表的一种算法，用所有可能的查询条件生成一个bitmap，在进行数据库查询之前会使用这个bitmap进行过滤，如果不在其中则直接过滤，从而减轻数据库层面的压力。guava中有实现BloomFilter算法。
2. 空值缓存：一种比较简单的解决办法，在第一次查询完不存在的数据后，将该key与对应的空值也放入缓存中，只不过设定为较短的失效时间，例如几分钟，这样则可以应对短时间的大量的该key攻击，设置为较短的失效时间是因为该值可能业务无关，存在意义不大，且该次的查询也未必是攻击者发起，无过久存储的必要，故可以早点失效。


### 缓存击穿
名词解释：热点数据刚好缓存失效，那么高并发的查询直接打到数据库

解决办法：
1. 将热点数据设置为永远不过期；
2. 加锁排队，只能有一个线程去构建缓存，设置合理的过期时间，其他线程再从缓存拿数据；








