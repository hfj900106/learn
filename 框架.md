### springboot启动流程
Springboot的启动，主要创建了配置环境(environment)、事件监听(listeners)、应用上下文(applicationContext)，并基于以上条件，在容器中开始实例化我们需要的Bean，至此，通过SpringBoot启动的程序已经构造完成。



### 分布式
关于分布式的一系列问题【http://www.wangzha.tech/archives/distributed-system-interview】

#### 分布式事务了解吗？你们是如何解决分布式事务问题的？
[http://www.wangzha.tech/archives/distributed-transaction]

分布式事务的实现主要有以下 5 种方案：
1. TCC 方案
2. 可靠消息最终一致性方案
3. XA 方案（不推荐）
4. 本地消息表（不推荐）
5. 最大努力通知方案

###### TCC（Try、Confirm、Cancel）
Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。
Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。
Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。

这种方案说实话几乎很少人使用，自己手写回滚逻辑，或者是补偿逻辑，代价太大，业务代码很难维护。
一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。

###### 可靠消息最终一致性方案

直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。
大概的意思就是：
1. A系统先发送一个 prepared 消息到 mq，如果消息发送失败那么就直接取消操作；如果发送成功，那么接着执行本地事务，事务实行成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；

2. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；

3. mq 会自动定时轮询所有 prepared 消息并回调你的接口，确认这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？通常你的接口接口可以查下数据库看之前本地事务是否执行，如果回滚了，那么告诉mq回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。

4. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。

这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。


###### XA（二段提交）（不推荐）
适用于单模块对应多个数据库的应用，存在一个类似管理器的概念，管理器在提交事务之前会先确认是否每个数据库都已经准备好，都ok的情况下再正式提交事务；如果有一个不ok，回滚事务；
缺点：严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景；

###### 本地消息表（不推荐）
这个大概意思是这样的：
A 系统在自己本地一个事务里操作同时，插入一条数据到消息表；
接着 A 系统将这个消息发送到 MQ 中去；
B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息；
B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态；
如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理；
这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。
这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的，会导致如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。

###### 最大努力通知方案
这个方案的大致意思就是：

系统 A 本地事务执行完之后，发送个消息到 MQ；
这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；
要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。

###### 你们公司是如何处理分布式事务的？
如果你真的被问到，可以这么说，我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于阿里的 RocketMQ 来实现分布式事务。

### 保证接口幂等性
这个不是技术问题，这个没有通用的一个方法，这个应该结合业务来保证幂等性。

所谓幂等性，就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，比如不能多扣款、不能多插入一条数据、不能将统计值多加了 1。这就是幂等性。

其实保证幂等性主要是三点：

对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。
每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。
每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。
实际运作过程中，你要结合自己的业务来，比如说利用 redis，用 orderId 作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款。

### 保证分布式服务的有序性
首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个内存队列里去，强制排队，这样来确保他们的顺序性。

但是这样引发的后续问题就很多，比如说要是某个订单对应的请求特别多，造成某台机器成热点怎么办？解决这些问题又要开启后续一连串的复杂技术方案......曾经这类问题弄的我们头疼不已，所以，还是建议什么呢？

最好是比如说刚才那种，一个订单的插入和删除操作，能不能合并成一个操作，就是一个删除，或者是什么，避免这种问题的产生。

### dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
【http://www.wangzha.tech/archives/dubbo-load-balancing】
dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡；
网络通信、序列化：dubbo 协议、长连接、NIO、hessian 序列化协议；
负载均衡策略、集群容错策略、动态代理策略：dubbo 跑起来的时候一些功能是如何运转的？怎么做负载均衡？怎么做集群容错？怎么生成动态代理？
dubbo SPI 机制：你了解不了解 dubbo 的 SPI 机制？如何基于 SPI 机制对 dubbo 进行扩展？

###### 负载均衡策略：
1. random loadbalance（默认，随机，按权重随机）
随机策略：
1.1 如果总权重大于0并且权重不相同，就生成一个1~totalWeight(总权重数)的随机数，然后再把随机数和所有的权重值一一相减得到一个新的随机数，直到随机 数小于0，那么此时访问的服务器就是使得随机数小于0的权重所在的机器；
1.2 如果权重相同或者总权重数为0，就生成一个1~length(权重的总个数)的随机数，此时所访问的机器就是这个随机数对应的权重所在的机器

2.RoundRobin LoadBalance（轮询）
2.1 轮循，按公约后的权重设置轮循比率。
2.2 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。
2.3 轮询策略
2.3.1 如果权重不一样时，获取一个当前的权重基数，然后从权重集合中筛选权重大于当前权重基数的集合，如果筛选出的集合的长度为1，此时所访问的机器就是集合里面的权重对应的机器
2.3.2 如果权重一样时就取模轮循

3、LeastActive LoadBalance
3.1 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差(调用前的时刻减去响应后的时刻的值)。
3.2 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大

4、ConsistentHash LoadBalance
4.1 一致性 Hash，相同参数的请求总是发到同一提供者。
4.2 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。
4.3 缺省只对第一个参数 Hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />
4.4 缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />

###### dubbo 集群容错策略
failover cluster 模式
失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器）

failfast cluster模式
一次调用失败就立即失败，常见于写操作。（调用失败就立即失败）

failsafe cluster 模式
出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

failback cluster 模式
失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

forking cluster 模式
并行调用多个 provider，只要一个成功就立即返回。

broadcacst cluster
逐个调用所有的 provider。

###### dubbo动态代理策略
默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。

### 深入理解SPI机制
【https://www.jianshu.com/p/3a3edbcd8f24】
SPI 全称为 (Service Provider Interface) ,是JDK内置的一种服务提供发现机制。 目前有不少框架用它来做服务的扩展发现， 简单来说，它就是一种动态替换发现的机制， 举个例子来说， 有个接口，想运行时动态的给它添加实现，你只需要添加一个实现。
具体是在JAR包的"src/META-INF/services/"目录下建立一个文件，文件名是接口的全限定名，文件的内容可以有多行，每行都是该接口对应的具体实现类的全限定名.
这一机制为很多框架扩展提供了可能，比如在Dubbo、JDBC中都使用到了SPI机制。


### 分布式锁
###### zookeeper创建临时有序节点
1. 多个线程竞争锁，就是按顺序在锁节点下创建一个接一个的临时有序子节点；
2. 若果不是第一个节点则监听前一个节点；
3. 如果自己前面一个节点释放，则往前移一位；
4. 所释放时会通知监听这个锁的监听器，监听器通知对应节点尝试获取锁；
5. 如果线程所在的客户端宕机，那么zk是可以感知到的，会删除对应的节点；

番外：Curator框架已经实现zk的封装，可以参考

###### redis  set Nx px + lua 脚本delete + 定时器
[https://www.cnblogs.com/lhh-north/p/11047252.html]
1. 加锁, 过期时间为N秒
2. 如果加锁成功, 则开启一个定时器
3. 定时器一直在执行, 每过了X(X < N, 一般可配置)秒, 就给这个锁延长Y (Y > X, 一般可配置)秒
4. 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
```
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```
5. 释放锁的时候, 把定时器删掉
6. RedLock 算法
```
REDLOCK的实现思路就是放弃redis的主从结构, 使用N(一般是5)个redis实例来保证可用性;
  1. 计算当前时间戳CUR_T
  2. 客户端逐一向N个redis获取锁.也就是把同一个KEY和VALUE分布写到每个redis实例中,过期时间为EX_T. 获取锁的时候还需要指一个时间:
  这次set命令的响应超时时间RESP_T. 其中RESP_T < EX_T. RESP_T的存在是为了避免某个redis实例已经挂了的时候,还在苦等它响应返回.
  3. 对于第2步中的任何一个redis实例, 如果RESP_T时间内没有返回, 或者set命令返回false, 则代表获取锁失败, 否则就是获取锁成功. 不管在当前实例获取锁成功还是失败, 都立马向下一个实例获取锁.
  4. N个redis都请求完后,计算总耗时(用加锁完成时间戳-CUR_T) ,满足至少有(N/2+1)个实例能获取到锁,而且总耗时小于锁的失效时间才算获取锁成功.
  5. 如果获取锁失败,要算所有的实例unlock释放锁.
```




### 分库分表中间件
###### mycat（proxy层方案）
mycat 这种 proxy 层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。

###### sharding-jdbc(当当开源的，属于 client 层方案)
sharding-jdbc 这种 client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 sharding-jdbc 的依赖；
###### 比较
通常来说，这两个方案其实都可以选用，但是我个人建议中小型公司选用 sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 mycat，然后大量项目直接透明使用即可

### 分库分表策略

###### 水平

###### 垂直

### LRU 算法 （Least Recently Used 最近最少使用）
【https://juejin.im/post/5c0392656fb9a049fb4366fa】
最先应用于Linux，用于内存管理，当我们的内存容量不够的时候需要回收内存清理数据，那应该以什么样的原则去清理呢，一般认为最近很少被访问的数据将来被访问的概率也比较底，所以先清除这部分数据回收内存。
具体的算法思想：
利用双向哈希链表按最后使用时间排序，新的哈希对会排在尾部，如果前面的哈希对呗访问，那么也会移到最尾，内存不足时会先清除前面的数据，这样最近常被使用的数据得以保留。

# MQ 连环问

#### 用消息中间件吗？为什么要用？有什么优缺点吗？
结合项目中的一些情景：
1. 解耦：用户在我们的平台上借款，需要和理财投资的资金进行匹配，那么当匹配成功后会推数据到账务系统，生成系列的账单，这时候要是直接调用那么系统间的耦合性比较强，这也体现了MQ的一个解耦的优点；
2. 异步：用户在平台上进行资料认证，这些数据会被同步到风控中心，那么直接调系统接口传送会增加响应时间，项目中把需要同步的信息先放到MQ中，等待风控来消费信息，异步处理的这个流程，缩短了用户的等待时间，这也体现了MQ的异步优点；
3. 削峰：

引入MQ 同时也会带来一些缺点：
1. 系统可用性降低：要是MQ挂了，那么可能导致整个系统崩溃；
2. 系统复杂性增高：要考虑MQ高可用、消息可靠传输、保证消息有序等等诸如此类的问题；
3. 一致性问题： A系统处理成功直接返回，人家以为你的请求直接成功了，如果B系统写入数据失败了，数据就不一致了；

对于MQ的选型：（待补充）

单机吞吐量： ActiveMQ 、 RabbitMQ 都是 万 级别；RocketMQ 、Kafka 10万 级别；
时效性：RabbitMQ 微秒 级别，其他都是 毫秒 级别；
可用性：ActiveMQ、RabbitMQ 可用性高，可基于主从高可用；RocketMQ 、Kafka 更高，基于分布式高可用；
消息可靠性： 
社区活跃度：综合来看，RabbitMQ 是首选；

ActiveMQ
ActiveMQ：万级吞吐量，ms时效性，有较低丢消息的可能行，社区不活跃，基于主从架构实现高可用性

RabbitMQ：万级吞吐量，微秒时效性，erlang开发，社区活跃，提供了完善的管理界面，基于主从架构实现高可用性

RocketMQ：10万级吞吐量，ms级，MQ功能较为完善，还是分布式的，扩展性好，阿里java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控

Kafka：10万级吞吐量，ms级，一般配合大数据类的系统来进行实时数据计算、日志采集等场景，非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用，这个特性天然适合大数据实时计算以及日志收集



#### 如何保证消息高可用？



### 如何保证消息不会被重复消费，幂等性？
1. 使用唯一键 
2. 生产者发送数据的时候，加一个全局唯一id，消费者在消费的时候，用redis判断，这条数据有没有被消费过，消费过，就不在消费了

#### 如何保证消息的可靠性传输？如何处理消息丢失的问题？
数据丢失的情况一般分三种：发往MQ的路上丢失、MQ接收到消息还没来得及消费就丢失了、消费者拿到消息还没有来得及消费就丢失了；

生产者： 开始conform模式；
MQ： 开启持久化；
消费者： 关闭自动ack；

1. 针对发送方：开启 confirm 模式，每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
2. 针对mq服务器：这个你必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。
　设置持久化两个步骤：

　　2.1 创建 queue 的时候将其设置为持久化，这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
　　2.2 发送消息的时候将消息的 deliveryMode 设置为 2，就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。
所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。

3. 针对消费者：这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。


#### 如何保证消息的顺序性？



#### 消息延时、过期失效如何处理？积压过多（比如几百万条）如何处理？队列满了装不下如何处理？



#### 设计一个消息队列，如何进行架构设计？



# redis 连环问

### 缓存雪崩
名词解析：缓存服务宕机或者大部分key同一时间失效，导致大量的查询都落到数据库导致崩溃。

解决办法：
1. 针对同时失效场景：加锁排队，只能有一个线程去构建缓存，设置合理的过期时间，其他线程再从缓存拿数据；
2. 针对宕机场景：
    事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃；
    事中：本地 ehcache 缓存 + hystrix 限流 & 降级，避免 MySQL 被打死；
    事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据；
    
### 缓存穿透
名词解释：查询一个不存在的数据，那么缓存中是没有的，只能到数据库查，直接穿过缓存，要是被利用攻击，后果可想而已

解决办法：
1. bloom filter：类似于哈希表的一种算法，用所有可能的查询条件生成一个bitmap，在进行数据库查询之前会使用这个bitmap进行过滤，如果不在其中则直接过滤，从而减轻数据库层面的压力。guava中有实现BloomFilter算法。
2. 空值缓存：一种比较简单的解决办法，在第一次查询完不存在的数据后，将该key与对应的空值也放入缓存中，只不过设定为较短的失效时间，例如几分钟，这样则可以应对短时间的大量的该key攻击，设置为较短的失效时间是因为该值可能业务无关，存在意义不大，且该次的查询也未必是攻击者发起，无过久存储的必要，故可以早点失效。


### 缓存击穿
名词解释：热点数据刚好缓存失效，那么高并发的查询直接打到数据库

解决办法：
1. 将热点数据设置为永远不过期；
2. 加锁排队，只能有一个线程去构建缓存，设置合理的过期时间，其他线程再从缓存拿数据；

### redis持久化方式？优缺点？实现？

###### 方式（默认RDB）
1. RDB（Redis datebase）
是把当前内存中的数据集快照写入磁盘，也就是 Snapshot 快照（数据库中所有键值对数据）。恢复时是将快照文件直接读到内存里。

自动触发：
　　在 redis.conf 配置文件中的 SNAPSHOTTING 下：
save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存；
不需要持久化则save "" 或者 直接注释掉所有save；

手动触发：
save：会阻塞；bgsave:后台异步；
基本上都是bgsave

数据恢复：
将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可，redis就会自动加载文件数据至内存了。Redis 服务器在载入 RDB 文件期间，会一直处于阻塞状态，直到载入工作完成为止。

优势：
1.1 主线程会fork()一个线程进行存盘工作，主线程不需要IO，可以高效提供服务；
1.2 保存的是数据集，恢复速度快，适用备份和灾难恢复；

劣势：
2.1 宕机会丢失最后时刻未进行存盘的数据；
2.2 bgsave每次会fork子线程，没法做到实时持久化，频繁执行成本高，影响性能；

https://www.cnblogs.com/ysocean/p/9114268.html

2. AOF（append-only-file）

https://www.cnblogs.com/ysocean/p/9114267.html
对于数据完整性要求较高的可以用

对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。

触发配置：
在 redis.conf 配置文件的 APPEND ONLY MODE 下：
appendonly：默认值为no，也就是说redis 默认使用的是rdb方式持久化，如果想要开启 AOF 持久化方式，需要将 appendonly 修改为 yes。

数据恢复：同RDB，异常修复命令：redis-check-aof --fix

AOF重写：
为解决aof文件越写越大，占内存且恢复速度慢，Redis增加了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof 来重写。子线程直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。
触发条件在redis.conf 配置文件配置；

因为子进程在进行 AOF 重写期间，服务器进程依然在处理其它命令，这新的命令有可能也对数据库进行了修改操作，使得当前数据库状态和重写后的 AOF 文件状态不一致。为了解决这个数据状态不一致的问题，Redis 服务器设置了一个 AOF 重写缓冲区，这个缓冲区是在创建子进程后开始使用，当Redis服务器执行一个写命令之后，就会将这个写命令也发送到 AOF 重写缓冲区。当子进程完成 AOF 重写之后，就会给父进程发送一个信号，父进程接收此信号后，就会调用函数将 AOF 重写缓冲区的内容都写到新的 AOF 文件中。

优点：
1. 默认每秒同步一次，就是丢失也只是一秒的数据，
2. AOF 文件的格式可读性较强，不小心错用了 FLUSHALL 命令，在重写还没进行时，将最后的 FLUSHALL 命令去掉，然后再使用 AOF 来恢复数据。

缺点：
1. 相同数量的Redis，AOF文件的体积比RDB大；
2. 负载较高的情况下每秒一次的频率比较吃力，耗性能；
3. 存在一些RDB没有的bug，数据恢复速度不如RDB快；

###### 如何选择两种方式

数据完整性要求不是特别严格的场景可以选RDB；
推荐平时使用两种方式并存，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。Redis后期官方可能都有将两种持久化方式整合为一种持久化模型。

### 如何保证缓存数据库双写一致

先更新数据库，再删除缓存；

但是这种情况在缓存刚好失效且有并发的情况可能回造成脏数据：
1. 缓存失效
2. B线程先更新数据库（还未提交）；
3. A线程查询到旧数据，想要放到缓存（还没有放）；
4. B提交并去删除缓存（虽然此时缓存没有，但还是操作）；
5. A将数据放入缓存
这过程本来是应该缓存B的值，结果是旧数据，不过这种几率很小，因为写肯定会比读快很多，这样缓存会被B删掉，下次查询会得到新的数据；
如何解决上述并发问题？
首先，给缓存设有效时间是一种方案。其次，采用异步延时删除策略，保证读请求完成以后，再进行删除操作。

还有一个问题？要是缓存删除不成功怎么办？
（1）更新数据库数据
（2）数据库会将操作信息写入binlog日志当中
（3）订阅程序提取出所需要的数据以及key
（4）另起一段非业务代码，获得该信息
（5）尝试删除缓存操作，发现删除失败
（6）将这些信息发送至消息队列
（7）重新从消息队列中获得该数据，重试操作。
备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。至于oracle中，博主目前不知道有没有现成中间件可以使用。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。

### Redis内存淘汰策略

过期策略：定期删除+惰性删除
定期：redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定期遍历这个字典来删除到期的 key。
Redis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。
1. 从过期字典中随机 20 个 key；
2. 删除这 20 个 key 中已经过期的 key；
3. 如果过期的 key 比率超过 1/4，那就重复步骤 1；
惰性：用到的时候检查是否过期，要是过期则删除；
所以并不是过期了就会释放内存
###### 内存淘汰策略（六种）
要是没有设置过期时间，或者过期未清除的数据依旧占用内存，这时候Redis使用内存淘汰机制
1. no-eviction：不会淘汰（默认），内存到达设置的阈值之后不会进行数据淘汰，只能查询和删除，不能写入；
2. volatile-lru：针对设置了过期时间的数据，淘汰最近最少使用的key;
3. volatile-random：随机淘汰设置了过期时间的某个key；
4. volatile-ttl:淘汰剩余过期时间最少的key；
5. allkeys-lru：淘汰最近最少使用的key；
6. allkeys-random：随机淘汰键空间的某个key；
redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典。
过期字典的键是一个指针，这个指针指向键空间中的某个键对象。
过期字典的值是一个long类型整数，这个整数保存了键所指的数据库键过期时间，一个毫秒精度的Unix时间戳。

### redis 哨兵模式


##### 京东金融redis实践
【https://www.infoq.cn/article/jingdong-redis-practice/】



 






















