##### 主要学
10个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树；  
10个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。  

##### 时间复杂度
    时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。  

T(n) = O(f(n))  
T(n)：表示代码执行的时间  
f(n)：每行代码执行次数总和  
O：表示代码的执行时间T(n)与f(n)表达式成正比  ；O(1)表示常量级的复杂度，不是只执行一次  

分析： 
1. O这种复杂度表示方法只是表示一种变化趋势，而并非精确值，我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了，实际就是n趋于无穷大后的表达式的值。 
eg：T(n) = O(2n+2) ->  T(n) = O(n) ; T(n) = O(2n^2+2n+3) -> T(n) = O(n^2)  

看一段代码块  
```java
/**
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
*/
```
第二第三行代码可表示为 2^0 * 2^1 * 2^3 ...2^k = n  ---> 2^k = n --> 求k --> k=log2^n  --> T(n)=O(log2^n)   

2. 复杂度由两个(或者多个)数据的规模来决定  

再看一段
```java
/**
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
*/
```
从代码中可以看出，m和n是表示两个数据规模。我们无法事先评估m和n谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是O(m+n)。  
针对这种情况，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

##### 空间复杂度
    空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。  
看一段代码
```java
/**
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }
  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
*/
```
跟时间复杂度分析一样，我们可以看到，第2行代码中，我们申请了一个空间存储变量i，但是它是常量阶的，跟数据规模n没有关系，
所以我们可以忽略。第3行申请了一个大小为n的int类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是O(n)。
我们常见的空间复杂度就是O(1)、O(n)、O(n2 )；

##### 复杂度总结  
    复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，
    越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )
    此外，还有4个概念要了解：最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、
    平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）

##### 数组
    数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。
    
    线性表（Linear List）：顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。
    其实除了数组，链表、队列、栈等也是线性表结构。而与它相对立的概念是非线性表，比如二叉树、堆、图等。
    之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。
    
    第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。
    但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，
    就需要做大量的数据搬移工作。

    数组下标为何从0开始？
    1. 方便计算内存地址偏移量，减少不必要的计算；
    a[k]_address = base_address + k * type_size；
    2. 历史原因，模仿C语言；

    n维数据：可以当做是存储(n-1)维数组的单维数组，寻址：有aa[m][n]的多维数据（m行，n列），那么aa[i][j]的地址是 address = base_address + (i * n + j) * type_size
    
##### 数组与链表的区别
    1.数组内存地址是连续的，链表可以不连续
    2.数组内存大小固定，不足时再申请更大的内存地址然后将原数组复制到新地址再使用，链表本身没有大小限制，天然支持扩容
    3.数组插入删除慢，查找快；链表插入删除快查找慢
    4.链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，有可能导致频繁GC
    
##### CPU 缓存机制
“数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。
而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，
没办法有效预读。” 这里的CPU缓存机制指的是什么？为什么就数组更好了？

    CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。
    而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块并保存到CPU缓存中，
    然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，
    也就是CPU缓存存在的意义：为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。

对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到C
PU缓存这样执行速度会快于存储空间不连续的链表存储。

##### 如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？
回文字符串：关于中心左右对称的字符串

速度不同的两个指针A、B，A走一步，B走两步，A每走一步逆转元素的next方向，当快B走完的时候A刚好到中间，
然后从中间开始向两边遍历，比较元素是都相同，只要存在不同，那就不是回文字符串
注意：区分奇数偶数个元素
    
##### 递归
编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。      
递归代码要警惕堆栈溢出和重复计算

##### 排序涉及名词解释
原地排序：是指在排序过程中不申请多余的存储空间，只利用原来存储待排数据的存储空间进行比较和交换的数据排序。希尔排序、冒泡排序、插入排序、选择排序、堆排序、快速排序 都是。   
稳定排序：待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

##### 冒泡排序（Bubble Sort）
相邻比较，交换位置，每一轮都会有一个元素冒头，稳定排序，原地排序，最好时间复杂度O(n)，最坏O(n^2)，平均O(n^2)

##### 插入排序（Insertion Sort）
分已排序区间和未排序区间，比较，小的放前面，大的放后面，每轮都会这个元素的合适位置，稳定，原地，最好时间复杂度O(n)，最坏O(n^2)，平均O(n^2)

##### 选择排序（Selection Sort）
分已排序区间和未排序区间，从剩下未排序区拿出一个最小值和已排序末尾第一个未排序元素交换位置，成为已分区的新末尾，非稳定，原地，最好、最坏时间复杂度都是 O(n^2)

    冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是O(n2)，比较高，适合小规模数据的排序  
    归并排序和快速排序时间复杂度为O(nlogn)，适合大规模的数据排序
   
##### 归并排序算法
low，mid，hight，左右递归分组排序，合并，左右有剩余的直接copy到原始序列，时间复杂度 O(nlogn)

##### 快速排序算法
如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot（分区点）。

遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，
数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的，中间是pivot，后面的q+1到r之间是大于pivot的。
根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。终止条件：p >= r

###### 线性排序 - 桶排序
桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。

比如说我们有10GB的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百MB，没办法一次性把10GB的数据都加载到内存中。这个时候该怎么办呢？
   1. 扫描所有文件得到排序数据的范围
   2. 根据范围划分桶（存储文件）的个数，并将数据放进桶
   3. 单个桶的文件超过内存可以用的合适值，那么继续对这个桶进行拆分 
   4. 依次将桶的数据读入内存进行排序，并合并到一个文件中，得到有序的数据文件  
   
##### 计数排序

##### 基数排序

##### 二分法查找
一种针对有序数据的高效查找算法，二分查找，它的时间复杂度是O(logn)；
核心思想有点类似分治思想,即每次都通过跟区间中的中间元素对比，根据大小将待查找的区间缩减为对应的一半，
直到找到要查找的元素，或者区间被缩小为0。   
   
##### 跳表


##### 散列表
散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。
散列函数设计的基本要求：  
散列函数计算得到的散列值是一个非负整数；  
如果key1 = key2，那hash(key1) == hash(key2)；  
如果key1 ≠ key2，那hash(key1) ≠ hash(key2)。  

###### 散列冲突  
再好的散列函数也无法避免散列冲突。那究竟该如何解决散列冲突问题呢？我们常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。
开放寻址：线性探测、二次方探测、双重散列  
链表法：链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。我们来看这个图，
在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，
所有散列值相同的元素我们都放到相同槽位对应的链表中。  

##### 哈希算法及应用

##### 二叉树
满二叉树，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点
完全二叉树，叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大

存储：链式、基于数组顺序存储（X存在i的位置，那么2*i 的位置是左子节点，2*i+1 右子节点,根节点会存储在下标为1的位置）
完全二叉树，那用数组存储，最省空间（堆其实就是一种完全二叉树，最常用的存储方式就是数组）

###### 二叉树的遍历：

前序 任意节点->左子树->右子树  
中序 左子树->任意节点->右子树  
后序 左子树->右子树->任意节点  

中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是O(n)，非常高效  
总结：都是先左再右，任意节点在前面就是前序，在中间就是中序，在后面就是后序 

##### 二叉查找树
为了实现快速查找而生的树，所有左子节点小于中间节点，右节点大于中间节点，它支持快速插入、删除、查找操作，各个操作的时间复杂度跟树的高度成正比，理想情况下，时间复杂度是O(logn)。

###### 查找
取根节点，如果比根节点小，往左子节点递归查询，如果比根节点大，往右子节点递归查询  
代码详见testDemo  

###### 插入
从根节点开始，依次比较要插入的数据和节点的大小关系。如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；
如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；
如果不为空，就再递归遍历左子树，查找插入位置。

###### 删除
1. 要删除的节点A 没有子节点，update父节点原本指向A的指针为null；  
2. 要删除的节点A 只有一个子节点（只有左子节点或者右子节点），update父节点中原本指向A的指针，让它指向A节点的子节点就可以了；  
3. 要删除的节点A 只有两个子节点，要找到A节点的右子树中的最小节点，把它的数据替换到要删除的节点上。然后再删除掉这个最小节点（那么就变成了以上两点，删除的节点没有子节点或者有一个右子节点），因为最小节点肯定没有左子节点，右节点（存在的话）会在删除后找到自己的位置；   

###### 缺点
1.极端情况会退化成链表，时间复杂度变成O(n)，未解决这个问题，衍生了“平衡二叉查找树”，也叫“平衡二叉树”

##### 平衡二叉树
二叉树中任意一个节点的左右子树的高度相差不能大于1，并且左右两个子树都是一棵平衡二叉树，常见的平衡二叉树包括 AVL树、红黑树；

##### 红黑树
1.根节点-黑色
2.叶子结点-黑色空节点、不存数据
3.红色节点不能相邻
4.根节点去到任意一个叶子结点必须经过相同个数的黑色节点

##### 堆
1.满足完全二叉树（区别前面讲的二叉查找树）
2.堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值
对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作“小顶堆”。     
备注：数组中下标为$i$的节点的左子节点，就是下标为$i*2$的节点，右子节点就是下标为$i*2+1$的节点，父节点就是下标为$\frac{i}{2}$的节点（frac取整）。
###### 插入
插入元素可能不满足大堆或者小堆的定义，需要堆化，插入元素与父节点比较大小，根据结果是否交换位置，从下往上比较，直到找到合适位置   

###### 删除
用堆的最后一个元素替换要删除的元素，然后再自上而下找到合适的位置

###### 堆排序
建堆->排序  
建堆 从第一个非叶子节点开始，从下往上比较，依次堆化就行了  
排序 将堆顶元素放与最后一个数组元素交换，堆化，再用新的堆顶与n-1的元素交换，类推，直到数组有序  

### 图
顶点、边、度（顶点连接的边数）、无向图、有向图、入度（箭头指向顶点的边数）、出度（箭头从顶点指出去的边数）、带权图

### 如何在内存中存储图这种数据结构呢？
1.邻接矩阵：邻接矩阵的底层依赖一个二维数组  
2.邻接表：


### 算法思想
贪心、分治、回溯、动态规划

贪心：每次都选一个对期望值贡献最大的选项，最后看看是不是最理想，若不是就不用贪心算法  
分治：

### 广度优先算法、深度优先算法
广度优先搜索，通俗的理解就是，地毯式层层推进，从起始顶点开始，依次往外遍历。广度优先搜索需要借助队列来实现，遍历得到的路径就是，起始顶点到终止顶点的最短路径。  
深度优先搜索用的是回溯思想，非常适合用递归实现。换种说法，深度优先搜索是借助栈来实现的。  
在执行效率方面，深度优先和广度优先搜索的时间复杂度都是O(E)，空间复杂度是O(V)。

### 字符串匹配算法
BF、RK（简单好理解）  
BM、KMP（难理解但是更高效）  
在字符串A中查找字符串B，那字符串A就是 主串，字符串B就是 模式串

#### RK算法是BF算法的改进，它巧妙借助了哈希算法，让匹配的效率有了很大的提升。那RK算法是如何借助哈希算法来实现高效字符串匹配的呢？

#### BF 算法
BF算法中的BF是Brute Force的缩写，中文叫作暴力匹配算法。  
我们把主串的长度记作n，模式串的长度记作m。因为我们是在主串中查找模式串，所以n>m。  
思想：在主串中，检查起始位置分别是0、1、2…n-m且长度为m的n-m+1个子串，看有没有跟模式串匹配的，暴力匹配。时间复杂度也比较高，是O(n*m)

#### RK 算法
我们通过哈希算法对主串中的n-m+1个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。RK算法的时间复杂度是O(n)，极端情况下，哈希算法大量冲突，时间复杂度就退化为O(n*m)。  

哈希计算巧妙设计，比如要处理的字符串只包含a～z这26个小写字母，那我们就用二十六进制来表示一个字符串。我们把a～z这26个字符映射到0～25这26个数字，a就表示0，b就表示1，以此类推，z表示25。26个字母->26进制->转成10进制比较，一个子串的哈希值跟模式串的哈希值相等的时候，我们只需要再对比一下子串和模式串本身就好了

#### BM 算法（高效）
从模式串的末尾往前倒着匹配；性能是著名的KMP算法的3到4倍；我们可以只用 好后缀规则 来实现BM算法。

坏字符规则：（不可单独使用，需结合好后缀，会出现si-xi<0 的情况：主串“aaaaa”，模式串“baa”，诸如此类）  
当遇到坏字符时，要计算往后移动的位数si-xi  
当我们发现某个字符没法匹配的时候。我们把这个没有匹配的字符叫作坏字符（主串中的字符）
当发生不匹配的时候，我们把坏字符对应的模式串中的字符下标记作si。如果坏字符在模式串中存在，我们把这个坏字符在模式串中的下标记作xi（如果有多个，取下标比较大的）。如果不存在，我们把xi记作-1。那模式串往后移动的位数就等于si-xi。（注意，我这里说的下标，都是字符在模式串的下标）。  

好后缀规则：（可以单独使用）  
模式串中下标比坏字符下标大的字符串（能匹配）是 好后缀，标识{u}。我们拿它在模式串中查找，如果找到了另一个跟{u}相匹配的子串{u*}，那我们就将模式串滑动到子串{u*}与主串中{u}对齐的位置。如果在模式串中找不到另一个等于{u}的子串，从好后缀的后缀子串中，找一个最长的并且能跟模式串的前缀子串匹配的，假设是{v}，然后将模式串滑动到如图所示的位置。

###### 当模式串和主串中的某个字符不匹配的时候，如何选择用好后缀规则还是坏字符规则，来计算模式串往后滑动的位数？  
可以分别计算好后缀和坏字符往后滑动的位数，然后取两个数中最大的，作为模式串往后滑动的位数。这种处理方法还可以避免我们前面提到的，根据坏字符规则，计算得到的往后滑动的位数，有可能是负数的情况。好后缀规则可以独立于坏字符规则使用。因为坏字符规则的实现比较耗内存，为了节省内存，我们可以只用好后缀规则来实现BM算法。

#### KMP 算法（高效）


### 位图（BitMap）
位图的原理：在位图中采用比特位表示对应的元素存在或者不存在，0：不存在 1：存在；  
假如用byte[]来存储，那么一个byte（8bit）可以存8个数据，byteIndex = k/8; bitIndex = k%8; 数据k将被存在byteIndex的bitIndex的bit位上；

假如有1千万个数据，数据范围在1-1亿之间，现在需要查找某个数据是不是在这一千万的数据之中，可以用位图实现，创建大小为一亿的位图，将数据对应的下标二进制位设置为1，数据没有对应上的下标二进制位为0，那么查找数据时只要单端这个数据的二进制位上是不是1即可。要是这数据用正常的java基础类型存储，那么会比较耗内存，所以在数据量和数据范围差距不是很大的情况下用位图省内存，反之如果数据范围远大于数据量的时候（比如一千万数据，范围在1-10亿）比较耗内存；这时候考虑布隆过滤器；

### 布隆过滤器
省空间，是位图的升级，使用K个哈希函数，对同一个数字进行求哈希值，那会得到K个不同的哈希值，分别记作$X_{1}$，$X_{2}$，$X_{3}$，…，$X_{K}$。把这K个数字作为位图中的下标，将对应的BitMap[$X_{1}$]，BitMap[$X_{2}$]，BitMap[$X_{3}$]，…，BitMap[$X_{K}$]都设置成true，用K个二进制位，来表示一个数字的存在。只要有一个不是true，那么结果就是false。查找也是同样的策略。  
缺点：还是会存在hash冲突造成误判，不过仅仅是会对存在的情况误判（一个数据本身不存在却能被判定为存在），要是判定为不存在，那么一定是不存在；布隆过滤器的误判率，主要跟哈希函数的个数、位图的大小有关
适用场景：布隆过滤器非常适合这种不需要100%准确的、允许存在小概率误判的大规模判重场景。比如网页爬虫的去重。

### 向量
可以用 多维向量 解决相似度喜好相近之类的推荐问题，利用欧几里得距离求最近则最优解



