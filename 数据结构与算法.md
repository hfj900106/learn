##### 主要学
10个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树；  
10个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。  

##### 时间复杂度
    时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。  

T(n) = O(f(n))  
T(n)：表示代码执行的时间  
f(n)：每行代码执行次数总和  
O：表示代码的执行时间T(n)与f(n)表达式成正比  ；O(1)表示常量级的复杂度，不是只执行一次  

分析： 
1. O这种复杂度表示方法只是表示一种变化趋势，而并非精确值，我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了，实际就是n趋于无穷大后的表达式的值。 
eg：T(n) = O(2n+2) ->  T(n) = O(n) ; T(n) = O(2n^2+2n+3) -> T(n) = O(n^2)  

看一段代码块  
```java
/**
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
*/
```
第二第三行代码可表示为 2^0 * 2^1 * 2^3 ...2^k = n  ---> 2^k = n --> 求k --> k=log2^n  --> T(n)=O(log2^n)   

2. 复杂度由两个(或者多个)数据的规模来决定  

再看一段
```java
/**
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
*/
```
从代码中可以看出，m和n是表示两个数据规模。我们无法事先评估m和n谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是O(m+n)。  
针对这种情况，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

##### 空间复杂度
    空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。  
看一段代码
```java
/**
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }
  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
*/
```
跟时间复杂度分析一样，我们可以看到，第2行代码中，我们申请了一个空间存储变量i，但是它是常量阶的，跟数据规模n没有关系，
所以我们可以忽略。第3行申请了一个大小为n的int类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是O(n)。
我们常见的空间复杂度就是O(1)、O(n)、O(n2 )；

##### 复杂度总结  
    复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，
    越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )
    此外，还有4个概念要了解：最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、
    平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）

##### 数组
    数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。
    
    线性表（Linear List）：顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。
    其实除了数组，链表、队列、栈等也是线性表结构。而与它相对立的概念是非线性表，比如二叉树、堆、图等。
    之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。
    
    第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。
    但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，
    就需要做大量的数据搬移工作。

    数组下标为何从0开始？
    1. 方便计算内存地址偏移量，减少不必要的计算；
    a[k]_address = base_address + k * type_size；
    2. 历史原因，模仿C语言；

    n维数据：可以当做是存储(n-1)维数组的单维数组，寻址：有aa[m][n]的多维数据，那么aa[i][j]的地址是 address = base_address + (i * n + j) * type_size
    
##### 数组与链表的区别
    1.数组内存地址是连续的，链表可以不连续
    2.数组内存大小固定，不足时再申请更大的内存地址然后将原数组复制到新地址再使用，链表本身没有大小限制，天然支持扩容
    3.数组插入删除慢，查找快；链表插入删除快查找慢
    4.链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，有可能导致频繁GC
    
##### CPU 缓存机制
“数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。
而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，
没办法有效预读。” 这里的CPU缓存机制指的是什么？为什么就数组更好了？

    CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。
    而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块并保存到CPU缓存中，
    然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，
    也就是CPU缓存存在的意义：为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。

对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到C
PU缓存这样执行速度会快于存储空间不连续的链表存储。

##### 如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？
回文字符串：关于中心左右对称的字符串

速度不同的两个指针A、B，A走一步，B走两步，A每走一步逆转元素的next方向，当快B走完的时候A刚好到中间，
然后从中间开始向两边遍历，比较元素是都相同，只要存在不同，那就不是回文字符串
注意：区分奇数偶数个元素
    
##### 递归
编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。      
递归代码要警惕堆栈溢出和重复计算

##### 排序涉及名词解释
原地排序：是指在排序过程中不申请多余的存储空间，只利用原来存储待排数据的存储空间进行比较和交换的数据排序。希尔排序、冒泡排序、插入排序、选择排序、堆排序、快速排序 都是。   
稳定排序：待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

##### 冒泡排序（Bubble Sort）
相邻比较，交换位置，每一轮都会有一个元素冒头，稳定排序，原地排序，最好时间复杂度O(n)，最坏O(n^2)，平均O(n^2)

##### 插入排序（Insertion Sort）
分已排序区间和未排序区间，比较，小的放前面，大的放后面，每轮都会这个元素的合适位置，稳定，原地，最好时间复杂度O(n)，最坏O(n^2)，平均O(n^2)

##### 选择排序（Selection Sort）
分已排序区间和未排序区间，从剩下未排序区拿出一个最小值和已排序末尾第一个未排序元素交换位置，成为已分区的新末尾，非稳定，原地，最好、最坏时间复杂度都是 O(n^2)

    冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是O(n2)，比较高，适合小规模数据的排序  
    归并排序和快速排序时间复杂度为O(nlogn)，适合大规模的数据排序
   
##### 归并排序算法
low，mid，hight，左右递归分组排序，合并，左右有剩余的直接copy到原始序列，时间复杂度 O(nlogn)

##### 快速排序算法
如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot（分区点）。

遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这一步骤之后，
数组p到r之间的数据就被分成了三个部分，前面p到q-1之间都是小于pivot的，中间是pivot，后面的q+1到r之间是大于pivot的。
根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。终止条件：p >= r

###### 线性排序 - 桶排序
桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。

比如说我们有10GB的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百MB，没办法一次性把10GB的数据都加载到内存中。这个时候该怎么办呢？
   1. 扫描所有文件得到排序数据的范围
   2. 根据范围划分桶（存储文件）的个数，并将数据放进桶
   3. 单个桶的文件超过内存可以用的合适值，那么继续对这个桶进行拆分 
   4. 依次将桶的数据读入内存进行排序，并合并到一个文件中，得到有序的数据文件  
   
##### 计数排序

##### 基数排序

##### 二分法查找
一种针对有序数据的高效查找算法，二分查找，它的时间复杂度是O(logn)；
核心思想有点类似分治思想,即每次都通过跟区间中的中间元素对比，根据大小将待查找的区间缩减为对应的一半，
直到找到要查找的元素，或者区间被缩小为0。   
   
##### 跳表


##### 散列表
散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。
散列函数设计的基本要求：  
散列函数计算得到的散列值是一个非负整数；  
如果key1 = key2，那hash(key1) == hash(key2)；  
如果key1 ≠ key2，那hash(key1) ≠ hash(key2)。  

###### 散列冲突  
再好的散列函数也无法避免散列冲突。那究竟该如何解决散列冲突问题呢？我们常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。
开放寻址：线性探测、二次方探测、双重散列  
链表法：链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。我们来看这个图，
在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，
所有散列值相同的元素我们都放到相同槽位对应的链表中。  

##### 哈希算法及应用

##### 二叉树
满二叉树，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点
完全二叉树，叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大

存储：链式、基于数组顺序存储（X存在i的位置，那么2*i 的位置是左子节点，2*i+1 右子节点,根节点会存储在下标为1的位置）
完全二叉树，那用数组存储，最省空间（堆其实就是一种完全二叉树，最常用的存储方式就是数组）

###### 二叉树的遍历：

前序 任意节点->左子树->右子树  
中序 左子树->任意节点->右子树  
后序 左子树->右子树->任意节点  

中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是O(n)，非常高效  
总结：都是先左再右，任意节点在前面就是前序，在中间就是中序，在后面就是后序 

##### 二叉查找树
为了实现快速查找而生的树，所有左子节点小于中间节点，右节点大于中间节点，它支持快速插入、删除、查找操作，各个操作的时间复杂度跟树的高度成正比，理想情况下，时间复杂度是O(logn)。

###### 查找
取根节点，如果比根节点小，往左子节点递归查询，如果比根节点大，往右子节点递归查询  
代码详见testDemo  

###### 插入
从根节点开始，依次比较要插入的数据和节点的大小关系。如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；
如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；
如果不为空，就再递归遍历左子树，查找插入位置。

###### 删除
1. 要删除的节点A 没有子节点，update父节点原本指向A的指针为null；  
2. 要删除的节点A 只有一个子节点（只有左子节点或者右子节点），update父节点中原本指向A的指针，让它指向A节点的子节点就可以了；  
3. 要删除的节点A 只有两个子节点，要找到A节点的右子树中的最小节点，把它的数据替换到要删除的节点上。然后再删除掉这个最小节点（那么就变成了以上两点，删除的节点没有子节点或者有一个右子节点），因为最小节点肯定没有左子节点，右节点（存在的话）会在删除后找到自己的位置；   

###### 缺点
1.极端情况会退化成链表，时间复杂度变成O(n)，未解决这个问题，衍生了“平衡二叉查找树”，也叫“平衡二叉树”

##### 平衡二叉树
二叉树中任意一个节点的左右子树的高度相差不能大于1，并且左右两个子树都是一棵平衡二叉树，常见的平衡二叉树包括 AVL树、红黑树；

##### 红黑树
1.根节点-黑色
2.叶子结点-黑色空节点、不存数据
3.红色节点不能相邻
4.根节点去到任意一个叶子结点必须经过相同个数的黑色节点

##### 堆
1.满足完全二叉树（区别前面讲的二叉查找树）
2.堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值
对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作“小顶堆”。     
     